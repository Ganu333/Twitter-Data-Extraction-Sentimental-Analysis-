{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fe8188",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-06T14:28:05.319879Z",
     "iopub.status.busy": "2023-03-06T14:28:05.319450Z",
     "iopub.status.idle": "2023-03-06T14:28:05.330926Z",
     "shell.execute_reply": "2023-03-06T14:28:05.329688Z"
    },
    "papermill": {
     "duration": 0.027533,
     "end_time": "2023-03-06T14:28:05.333902",
     "exception": false,
     "start_time": "2023-03-06T14:28:05.306369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd90bb6",
   "metadata": {
    "papermill": {
     "duration": 0.009726,
     "end_time": "2023-03-06T14:28:05.353753",
     "exception": false,
     "start_time": "2023-03-06T14:28:05.344027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hello!\n",
    "# We will perform Data extraction from twitter and then use that data to analysze the sentiments.\n",
    "# This project will be in Three parts: \n",
    "# 1)Data Extraction\n",
    "# 2)Data Pre - processing\n",
    "# 3)Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd222f",
   "metadata": {
    "papermill": {
     "duration": 0.009432,
     "end_time": "2023-03-06T14:28:05.373005",
     "exception": false,
     "start_time": "2023-03-06T14:28:05.363573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1) Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9943fef3",
   "metadata": {
    "papermill": {
     "duration": 0.010873,
     "end_time": "2023-03-06T14:28:05.393544",
     "exception": false,
     "start_time": "2023-03-06T14:28:05.382671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we will import \"Tweepy\" to extract data from twitter. Also for twitter data we need a Twitter developer account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4beadf",
   "metadata": {
    "papermill": {
     "duration": 0.009417,
     "end_time": "2023-03-06T14:28:05.412666",
     "exception": false,
     "start_time": "2023-03-06T14:28:05.403249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Packages to be imported "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b4aa1",
   "metadata": {
    "papermill": {
     "duration": 0.009433,
     "end_time": "2023-03-06T14:28:05.432104",
     "exception": false,
     "start_time": "2023-03-06T14:28:05.422671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tweepy = For twitter data extraction, Pandas = To fill the data in a table, re = To replace strings, datetime = To get the date from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c41493b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:28:05.453922Z",
     "iopub.status.busy": "2023-03-06T14:28:05.453097Z",
     "iopub.status.idle": "2023-03-06T14:28:18.355650Z",
     "shell.execute_reply": "2023-03-06T14:28:18.354067Z"
    },
    "papermill": {
     "duration": 12.916537,
     "end_time": "2023-03-06T14:28:18.358251",
     "exception": false,
     "start_time": "2023-03-06T14:28:05.441714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Tweepy\r\n",
      "  Downloading tweepy-4.12.1-py3-none-any.whl (101 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: oauthlib<4,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from Tweepy) (3.2.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /opt/conda/lib/python3.7/site-packages (from Tweepy) (2.28.2)\r\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from Tweepy) (1.3.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->Tweepy) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->Tweepy) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->Tweepy) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->Tweepy) (2022.12.7)\r\n",
      "Installing collected packages: Tweepy\r\n",
      "Successfully installed Tweepy-4.12.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb36ee3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:28:18.382490Z",
     "iopub.status.busy": "2023-03-06T14:28:18.381134Z",
     "iopub.status.idle": "2023-03-06T14:28:18.424142Z",
     "shell.execute_reply": "2023-03-06T14:28:18.422857Z"
    },
    "papermill": {
     "duration": 0.058045,
     "end_time": "2023-03-06T14:28:18.426965",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.368920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b0b20",
   "metadata": {
    "papermill": {
     "duration": 0.010294,
     "end_time": "2023-03-06T14:28:18.448077",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.437783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2015626c",
   "metadata": {
    "papermill": {
     "duration": 0.010262,
     "end_time": "2023-03-06T14:28:18.469092",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.458830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will use all the keys from our developer account.This step is called authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a90fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:28:18.492343Z",
     "iopub.status.busy": "2023-03-06T14:28:18.491898Z",
     "iopub.status.idle": "2023-03-06T14:28:18.499016Z",
     "shell.execute_reply": "2023-03-06T14:28:18.497380Z"
    },
    "papermill": {
     "duration": 0.021978,
     "end_time": "2023-03-06T14:28:18.501661",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.479683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = \"JVWwfHwPBzLoDc2DfFaFL5gmU\"\n",
    "api_key_secret = \"AeMHhW4ORfwU1nb8eWJg4PP7P8kULKOUPn37nrWFeH1E2W4pZn\"\n",
    "access_token = \"2943199105-fvKLhg03gbnMPTBAfMyiDWo8fm574aVsnAcSRml\"\n",
    "access_token_secret = \"Iu7NIQYPaXGURY8aeVVozGyV4QQOXZOYOrROp6Ad3641D\"\n",
    "\n",
    "#Authentication\n",
    "auth = tweepy.OAuthHandler(api_key,api_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda53ab",
   "metadata": {
    "papermill": {
     "duration": 0.010719,
     "end_time": "2023-03-06T14:28:18.523519",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.512800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# We will define a function to display the tweet and all the other tweet details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc9bbb",
   "metadata": {
    "papermill": {
     "duration": 0.010208,
     "end_time": "2023-03-06T14:28:18.544422",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.534214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "n = Tweet index ith_tweet = The details of tweet (We will define this further)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095b824a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:28:18.568472Z",
     "iopub.status.busy": "2023-03-06T14:28:18.567538Z",
     "iopub.status.idle": "2023-03-06T14:28:18.574583Z",
     "shell.execute_reply": "2023-03-06T14:28:18.573084Z"
    },
    "papermill": {
     "duration": 0.022662,
     "end_time": "2023-03-06T14:28:18.577748",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.555086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_tweet(n, ith_tweet):\n",
    "        print()\n",
    "        print(f\"Tweet {n}:\")\n",
    "        print(f\"Username:{ith_tweet[0]}\")\n",
    "        print(f\"Description:{ith_tweet[1]}\")\n",
    "        print(f\"Location:{ith_tweet[2]}\")\n",
    "        print(f\"Following Count:{ith_tweet[3]}\")\n",
    "        print(f\"Follower Count:{ith_tweet[4]}\")\n",
    "        print(f\"Total Tweets:{ith_tweet[5]}\")\n",
    "        print(f\"Retweet Count:{ith_tweet[6]}\")\n",
    "        print(f\"Tweet Text:{ith_tweet[7]}\")\n",
    "        print(f\"Hashtags Used:{ith_tweet[8]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a3bae",
   "metadata": {
    "papermill": {
     "duration": 0.010631,
     "end_time": "2023-03-06T14:28:18.599063",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.588432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Data Extraction : We will define a function to extract data, This data will be saved in a dataframe \"db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013f8fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:28:18.622643Z",
     "iopub.status.busy": "2023-03-06T14:28:18.622184Z",
     "iopub.status.idle": "2023-03-06T14:28:18.635139Z",
     "shell.execute_reply": "2023-03-06T14:28:18.633767Z"
    },
    "papermill": {
     "duration": 0.028199,
     "end_time": "2023-03-06T14:28:18.638108",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.609909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape(words, date_since, numtweet):\n",
    " \n",
    "        # Creating DataFrame using pandas\n",
    "        db = pd.DataFrame(columns=['username',\n",
    "                                   'description',\n",
    "                                   'location',\n",
    "                                   'following',\n",
    "                                   'followers',\n",
    "                                   'totaltweets',\n",
    "                                   'retweetcount',\n",
    "                                   'text',\n",
    "                                   'hashtags'])\n",
    " \n",
    "        # We are using .Cursor() to search\n",
    "        # through twitter for the required tweets.\n",
    "        # The number of tweets can be\n",
    "        # restricted using .items(number of tweets)\n",
    "        tweets = tweepy.Cursor(api.search_tweets,\n",
    "                               words, lang=\"en\",\n",
    "                               since_id=date_since,\n",
    "                               tweet_mode='extended').items(numtweet)\n",
    " \n",
    " \n",
    "        # .Cursor() returns an iterable object. Each item in\n",
    "        # the iterator has various attributes\n",
    "        # that you can access to\n",
    "        # get information about each tweet\n",
    "        list_tweets = [tweet for tweet in tweets]\n",
    " \n",
    "        # Counter to maintain Tweet Count\n",
    "        i = 1\n",
    " \n",
    "        # we will iterate over each tweet in the\n",
    "        # list for extracting information about each tweet\n",
    "        for tweet in list_tweets:\n",
    "                username = tweet.user.screen_name\n",
    "                description = tweet.user.description\n",
    "                location = tweet.user.location\n",
    "                following = tweet.user.friends_count\n",
    "                followers = tweet.user.followers_count\n",
    "                totaltweets = tweet.user.statuses_count\n",
    "                retweetcount = tweet.retweet_count\n",
    "                hashtags = tweet.entities['hashtags']\n",
    " \n",
    "                # Retweets can be distinguished by\n",
    "                # a retweeted_status attribute,\n",
    "                # in case it is an invalid reference,\n",
    "                # except block will be executed\n",
    "                try:\n",
    "                        text = tweet.retweeted_status.full_text\n",
    "                except AttributeError:\n",
    "                        text = tweet.full_text\n",
    "                hashtext = list()\n",
    "                for j in range(0, len(hashtags)):\n",
    "                        hashtext.append(hashtags[j]['text'])\n",
    " \n",
    "                # Here we are appending all the\n",
    "                # extracted information in the DataFrame\n",
    "                ith_tweet = [username, description,\n",
    "                             location, following,\n",
    "                             followers, totaltweets,\n",
    "                             retweetcount, text, hashtext]\n",
    "                db.loc[len(db)] = ith_tweet\n",
    " \n",
    "                # Function call to print tweet data on screen\n",
    "                display_tweet(i, ith_tweet)\n",
    "                i = i+1\n",
    "        filename = 'tweets_data.csv'\n",
    " \n",
    "        # we will save our database as a CSV file.\n",
    "        db.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27176110",
   "metadata": {
    "papermill": {
     "duration": 0.010191,
     "end_time": "2023-03-06T14:28:18.658955",
     "exception": false,
     "start_time": "2023-03-06T14:28:18.648764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# We will ask user to enter the tweets he wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5169500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:28:18.682082Z",
     "iopub.status.busy": "2023-03-06T14:28:18.681650Z",
     "iopub.status.idle": "2023-03-06T14:28:18.791878Z",
     "shell.execute_reply": "2023-03-06T14:28:18.790089Z"
    },
    "papermill": {
     "duration": 0.124029,
     "end_time": "2023-03-06T14:28:18.793515",
     "exception": true,
     "start_time": "2023-03-06T14:28:18.669486",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/1466190727.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Twitter HashTag to search for\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Date since The Tweets are required in yyyy-mm--dd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdate_since\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnumtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the no of tweets you want : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             raise StdinNotImplementedError(\n\u001b[0;32m-> 1175\u001b[0;31m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m             )\n\u001b[1;32m   1177\u001b[0m         return self._input_request(\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "words = input(\"Enter Twitter HashTag to search for\")\n",
    "print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
    "date_since = input()\n",
    "numtweet = int(input(\"Enter the no of tweets you want : \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ebc6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T13:58:20.878893Z",
     "iopub.status.busy": "2023-03-06T13:58:20.878416Z",
     "iopub.status.idle": "2023-03-06T13:58:20.884439Z",
     "shell.execute_reply": "2023-03-06T13:58:20.883070Z",
     "shell.execute_reply.started": "2023-03-06T13:58:20.878852Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# We will perform our task by Running the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb15ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T13:58:43.500303Z",
     "iopub.status.busy": "2023-03-06T13:58:43.499786Z",
     "iopub.status.idle": "2023-03-06T13:58:43.521399Z",
     "shell.execute_reply": "2023-03-06T13:58:43.519145Z",
     "shell.execute_reply.started": "2023-03-06T13:58:43.500256Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scrape(words, date_since, numtweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf30d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T13:59:04.601166Z",
     "iopub.status.busy": "2023-03-06T13:59:04.599911Z",
     "iopub.status.idle": "2023-03-06T13:59:04.641981Z",
     "shell.execute_reply": "2023-03-06T13:59:04.639195Z",
     "shell.execute_reply.started": "2023-03-06T13:59:04.601107Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Table = pd.read_csv('tweets_data.csv')\n",
    "Table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f2a7c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2) Data Pre processing¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad35ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can see here that the Text in the table contains (username,url and special char), We will eliminate these char. Also we need only the text for sentimental analysis, We will delete the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f097e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:00:30.872823Z",
     "iopub.status.busy": "2023-03-06T14:00:30.872303Z",
     "iopub.status.idle": "2023-03-06T14:00:30.898271Z",
     "shell.execute_reply": "2023-03-06T14:00:30.895552Z",
     "shell.execute_reply.started": "2023-03-06T14:00:30.872743Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Table = Table.drop(['Unnamed: 0','username','description','location','following','followers','totaltweets','retweetcount','hashtags'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eeed43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:00:21.671644Z",
     "iopub.status.busy": "2023-03-06T14:00:21.671133Z",
     "iopub.status.idle": "2023-03-06T14:00:21.692146Z",
     "shell.execute_reply": "2023-03-06T14:00:21.690006Z",
     "shell.execute_reply.started": "2023-03-06T14:00:21.671600Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a729c021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:02:35.550748Z",
     "iopub.status.busy": "2023-03-06T14:02:35.550259Z",
     "iopub.status.idle": "2023-03-06T14:02:35.556840Z",
     "shell.execute_reply": "2023-03-06T14:02:35.555133Z",
     "shell.execute_reply.started": "2023-03-06T14:02:35.550706Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# We will add a index column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ff81e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T14:02:59.202325Z",
     "iopub.status.busy": "2023-03-06T14:02:59.201863Z",
     "iopub.status.idle": "2023-03-06T14:02:59.225556Z",
     "shell.execute_reply": "2023-03-06T14:02:59.223638Z",
     "shell.execute_reply.started": "2023-03-06T14:02:59.202283Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Index = range(1,101)\n",
    "Table['Index']=Index\n",
    "Table.set_index('Index',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3abf56",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Cleaning Data\n",
    "\n",
    "We will use re library to delete the unwanted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26a810",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '',text)\n",
    "    text = re.sub(r'#', '',text)\n",
    "    text = re.sub(r'RT[\\s]+', '',text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '',text)\n",
    "    return text\n",
    "\n",
    "Table['text'] = Table['text'].apply(Clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b95b4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8c40d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf82221",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 3) Data Analysis (Sentimental Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18176f06",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "After cleaning data we will analysize the text into : Positive,Negative or Neutral For this we use TextBlob library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444fe37a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b020f5b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Creating a funnction to return the sentimenal values and then applying to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0a26a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getsubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def getpolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "Table['Subjectivity'] = Table['text'].apply(getsubjectivity)\n",
    "Table['Polarity'] = Table['text'].apply(getpolarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098dbcdf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Now we have got Subjectivity and Polarity score, We need to add a column where it shows whether the polarity is negative, positive or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76254e99",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getanalysis(score):\n",
    "    if score < 0 :\n",
    "        return \"Negative\"\n",
    "    elif score == 0 :\n",
    "        return \"Neutral\"\n",
    "    else :\n",
    "        return \"Positive\"\n",
    "\n",
    "Table['Analysis'] = Table['Polarity'].apply(getanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e8fc7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c974dff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We want to know what are the most common words occuring in Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa386d4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Negative_Table = Table[Table['Analysis'] == \"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d521c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Positive_Table = Table[Table['Analysis'] == \"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d918112",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Neutral_Table = Table[Table['Analysis'] == \"Neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4a3c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "To Extract most common words from the test we need to use wordcloud library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb8e95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b810e62a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "allwords = ' '.join([text for text in Table['text']])\n",
    "wordcloud = WordCloud(width = 500, height = 300, random_state = 21,max_font_size = 119).generate(allwords)\n",
    "\n",
    "plt.imshow(wordcloud,interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34db04",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Negativewords = ' '.join([text for text in Negative_Table['text']])\n",
    "wordcloud = WordCloud(width = 500, height = 300, random_state = 21,max_font_size = 119).generate(Negativewords)\n",
    "\n",
    "plt.imshow(wordcloud,interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e1b22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Positivewords = ' '.join([text for text in Positive_Table['text']])\n",
    "wordcloud = WordCloud(width = 500, height = 300, random_state = 21,max_font_size = 119).generate(Positivewords)\n",
    "\n",
    "plt.imshow(wordcloud,interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378fd57",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Neutralwords = ' '.join([text for text in Neutral_Table['text']])\n",
    "wordcloud = WordCloud(width = 500, height = 300, random_state = 21,max_font_size = 119).generate(Neutralwords)\n",
    "\n",
    "plt.imshow(wordcloud,interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b75268",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# We will finally use a Bar graph to show the number of positive, negative and neutral Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e35c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Table['Analysis'].value_counts()\n",
    "\n",
    "plt.title('Sentiment Analysis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "Table['Analysis'].value_counts().plot(kind='bar')\n",
    "plot.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e8779",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca35af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.721524,
   "end_time": "2023-03-06T14:28:19.528201",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-06T14:27:54.806677",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
